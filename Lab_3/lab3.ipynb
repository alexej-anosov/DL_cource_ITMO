{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-03-09T17:24:24.227170Z","iopub.status.busy":"2024-03-09T17:24:24.226479Z","iopub.status.idle":"2024-03-09T17:24:50.954883Z","shell.execute_reply":"2024-03-09T17:24:50.953521Z","shell.execute_reply.started":"2024-03-09T17:24:24.227127Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!pip install peft\n","!pip install jsonlines"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-09T17:24:50.957382Z","iopub.status.busy":"2024-03-09T17:24:50.957045Z","iopub.status.idle":"2024-03-09T17:25:09.248377Z","shell.execute_reply":"2024-03-09T17:25:09.247578Z","shell.execute_reply.started":"2024-03-09T17:24:50.957355Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-09 17:24:58.944244: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-09 17:24:58.944353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-09 17:24:59.073650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import torch.optim as optim\n","import torch.utils.data as data\n","import math\n","import copy\n","import os\n","import re\n","import random\n","import shutil\n","import numpy as np\n","from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n","from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:25:09.250111Z","iopub.status.busy":"2024-03-09T17:25:09.249509Z","iopub.status.idle":"2024-03-09T17:25:11.355888Z","shell.execute_reply":"2024-03-09T17:25:11.354800Z","shell.execute_reply.started":"2024-03-09T17:25:09.250054Z"},"trusted":true},"outputs":[],"source":["device = \"cuda\"\n","model_name_or_path = \"ai-forever/rugpt3medium_based_on_gpt2\"\n","tokenizer_name_or_path = \"ai-forever/rugpt3medium_based_on_gpt2\"\n","\n","\n","max_length = 256\n","lr = 3e-5\n","num_epochs = 20\n","iter_steps = 5000\n","batch_size = 4\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:25:11.358641Z","iopub.status.busy":"2024-03-09T17:25:11.358312Z","iopub.status.idle":"2024-03-09T17:35:20.433537Z","shell.execute_reply":"2024-03-09T17:35:20.432539Z","shell.execute_reply.started":"2024-03-09T17:25:11.358612Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"IlyaGusev/stihi_ru\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:35:20.434972Z","iopub.status.busy":"2024-03-09T17:35:20.434703Z","iopub.status.idle":"2024-03-09T17:35:30.608130Z","shell.execute_reply":"2024-03-09T17:35:30.606818Z","shell.execute_reply.started":"2024-03-09T17:35:20.434949Z"},"trusted":true},"outputs":[],"source":["from collections import Counter\n","labels = dataset['train']['author']\n","label_counts = Counter(labels)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:35:30.610177Z","iopub.status.busy":"2024-03-09T17:35:30.609711Z","iopub.status.idle":"2024-03-09T17:35:30.668776Z","shell.execute_reply":"2024-03-09T17:35:30.667858Z","shell.execute_reply.started":"2024-03-09T17:35:30.610139Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["None: 927782\n","Носильщик: 10811\n","Зевс: 8477\n","Станислав Прохоренко: 6788\n","Анатолий Смоляр: 4466\n","Май Тирас: 4258\n","Феликс Кац: 4188\n","Халида Шариф: 3930\n","Сергей Носов 8: 3687\n","Качалов Игорь: 3651\n"]}],"source":["k = 10  \n","top_k = label_counts.most_common(k)\n","for value, count in top_k:\n","    print(f\"{value}: {count}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:35:30.670928Z","iopub.status.busy":"2024-03-09T17:35:30.670236Z","iopub.status.idle":"2024-03-09T17:35:31.964222Z","shell.execute_reply":"2024-03-09T17:35:31.963128Z","shell.execute_reply.started":"2024-03-09T17:35:30.670889Z"},"trusted":true},"outputs":[],"source":["dataset = dataset['train'][:100000]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:35:31.967524Z","iopub.status.busy":"2024-03-09T17:35:31.967106Z","iopub.status.idle":"2024-03-09T17:37:02.311784Z","shell.execute_reply":"2024-03-09T17:37:02.310949Z","shell.execute_reply.started":"2024-03-09T17:35:31.967484Z"},"trusted":true},"outputs":[],"source":["train_data = []\n","test_data = []\n","for full_txt in dataset['text']:\n","    full_txt = '<s>'+full_txt+'</s>'\n","    if random.random()<0.1:\n","        for i in range(len(full_txt)//2000+1):\n","            txt = full_txt[2000*i:2000*(i+1)]\n","            tokenized_txt = tokenizer(txt)['input_ids']\n","            if len(tokenized_txt) > 100:\n","                test_data.append(tokenized_txt)\n","    else:\n","        for i in range(len(full_txt)//2000+1):\n","            txt = full_txt[2000*i:2000*(i+1)]\n","            tokenized_txt = tokenizer(txt)['input_ids']\n","            if len(tokenized_txt) > 100:\n","                train_data.append(tokenized_txt)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:37:02.313242Z","iopub.status.busy":"2024-03-09T17:37:02.312937Z","iopub.status.idle":"2024-03-09T17:37:02.320101Z","shell.execute_reply":"2024-03-09T17:37:02.319138Z","shell.execute_reply.started":"2024-03-09T17:37:02.313216Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(68694, 7545)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data), len(test_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:37:02.324268Z","iopub.status.busy":"2024-03-09T17:37:02.323897Z","iopub.status.idle":"2024-03-09T17:37:02.333724Z","shell.execute_reply":"2024-03-09T17:37:02.332806Z","shell.execute_reply.started":"2024-03-09T17:37:02.324226Z"},"trusted":true},"outputs":[],"source":["class MyDataLoader:\n","    def __init__(self, data1,  batch_size):\n","        self.batch_size = batch_size\n","        self.data =  data1\n","    \n","    def __iter__(self):\n","        return self\n","    \n","    def __next__(self):\n","        x = []\n","        y = []\n","        attention_mask = []\n","        \n","        batch = [self.data[i] for i in np.random.choice(len(self.data),self.batch_size)]\n","        \n","        for input_ids in batch:\n","            split_token = torch.randint(100, len(input_ids), (1,))\n","            x_item = input_ids[split_token-max_length:split_token]\n","            attention_mask_item = [0]*(max_length - len(x_item)) + [1]*len(x_item)\n","            x_item = [0]*(max_length - len(x_item)) + x_item\n","            x.append(x_item)\n","            attention_mask.append(attention_mask_item)\n","        \n","        output = {'input_ids': torch.tensor(x).to(device),\n","                  'attention_mask': torch.tensor(attention_mask).to(device)} \n","\n","        return output\n","\n","    \n","train_dataloader = MyDataLoader(train_data, batch_size=batch_size)\n","test_dataloader = MyDataLoader(test_data, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:37:02.335420Z","iopub.status.busy":"2024-03-09T17:37:02.334893Z","iopub.status.idle":"2024-03-09T17:37:11.131554Z","shell.execute_reply":"2024-03-09T17:37:11.130658Z","shell.execute_reply.started":"2024-03-09T17:37:02.335347Z"},"trusted":true},"outputs":[],"source":["peft_config = PrefixTuningConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, num_virtual_tokens=15)\n","\n","model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n","model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()\n","model = model.to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:37:11.133036Z","iopub.status.busy":"2024-03-09T17:37:11.132716Z","iopub.status.idle":"2024-03-09T17:37:11.139557Z","shell.execute_reply":"2024-03-09T17:37:11.138536Z","shell.execute_reply.started":"2024-03-09T17:37:11.133009Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:37:11.141500Z","iopub.status.busy":"2024-03-09T17:37:11.141145Z","iopub.status.idle":"2024-03-09T17:37:12.436576Z","shell.execute_reply":"2024-03-09T17:37:12.435639Z","shell.execute_reply.started":"2024-03-09T17:37:11.141475Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['ustustustustustustustustustustustustustustustustustustustustustustustustabustustust Tra Tra Tra Tra Tra Tra Tra Tra Traйте Tra,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, с,,, с, с,, с,,,,,,,,,,,, с с,, с, с,,, -, с - - - - - -::::::::::::: к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к кombombombomb кombombombombombombomb от от от от от от от от от от от,,,,,,,,,,,,,,,,, должны, должны должны должны должны должны должны должны должны должны должны \\n не \\n))) \\n)))))))) \\n \\n \\n))) \\n']\n"]}],"source":["batch  = next(iter(train_dataloader))\n","batch = {k: v.to(device) for k, v in batch.items()}\n","outputs = model(**batch, labels=batch[\"input_ids\"])\n","print(tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)[0])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T17:37:12.438459Z","iopub.status.busy":"2024-03-09T17:37:12.438059Z","iopub.status.idle":"2024-03-10T05:05:15.472748Z","shell.execute_reply":"2024-03-10T05:05:15.471547Z","shell.execute_reply.started":"2024-03-09T17:37:12.438425Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch=0: train_ppl=tensor(6537.7910, device='cuda:0') train_epoch_loss=tensor(8.7854, device='cuda:0') eval_ppl=tensor(7.7637, device='cuda:0') eval_epoch_loss=tensor(2.0495, device='cuda:0')\n",".,,,, много,,,ник,,рину, себеслед, что\n",",али\n",", кто,,\n","\n","ис,би,, не глазахпу,\n","\n","\n",",,ится, головойенно,\n","езда,,ёттиь,\n","\n"," меняка,\n","\n","неца,ел,\n","но,,\n","\n"," в,\n"," с\n","\n","\n"," в\n","\n","\n","epoch=1: train_ppl=tensor(8.3800, device='cuda:0') train_epoch_loss=tensor(2.1258, device='cuda:0') eval_ppl=tensor(6.1479, device='cuda:0') eval_epoch_loss=tensor(1.8161, device='cuda:0')\n","\n",",\n","\n",",,\n",",\n",",лю,,рил,\n","\n"," в, глазахет,у,\n","ить,,\n","И, и,\n","алила,,\n","Их, мной,\n","\n"," вка,л\n",", глазахле,И тебя,ой,\n","Иалось,\n",",нув,И в, тобой.\n","И в дня,шьИ меняку,\n","И не мнойчною..Ижно меня.но\n","Иишь ври,ки\n","\n","\n","\n","\n","epoch=2: train_ppl=tensor(7.0820, device='cuda:0') train_epoch_loss=tensor(1.9576, device='cuda:0') eval_ppl=tensor(5.4332, device='cuda:0') eval_epoch_loss=tensor(1.6925, device='cuda:0')\n","\n","\n","\n","epoch=3: train_ppl=tensor(6.3734, device='cuda:0') train_epoch_loss=tensor(1.8521, device='cuda:0') eval_ppl=tensor(4.9168, device='cuda:0') eval_epoch_loss=tensor(1.5927, device='cuda:0')\n","\n","\n","\n","epoch=4: train_ppl=tensor(5.8910, device='cuda:0') train_epoch_loss=tensor(1.7734, device='cuda:0') eval_ppl=tensor(4.6481, device='cuda:0') eval_epoch_loss=tensor(1.5365, device='cuda:0')\n","\n","б\n",",\n","ь,,\n","Иб, сердце,\n","лю, мороз,\n","Иблю тебя что ты тебя,И,, снегомве\n","\n","\n","Иблю,,\n"," солнце,сть,И в,лые лучи,\n","Иблю, на солнцеьне.И в,. глаза.\n","\n","Иблю,,,\n","та..\n","И солнце,ых песенравлилей.\n","И нимидами,,.\n","\n","Иблю я,когданой,,\n","Ивои голос,\n","\n","\n","epoch=5: train_ppl=tensor(5.6202, device='cuda:0') train_epoch_loss=tensor(1.7264, device='cuda:0') eval_ppl=tensor(4.5691, device='cuda:0') eval_epoch_loss=tensor(1.5193, device='cuda:0')\n",",\n","\n","ваю,,сти,\n","\n"," в,\n",", враги,\n","И в хватаетютют,,\n"," а что,\n","Итоваю,,, снова,\n","И не этого не какти, не и не бывает.\n","И не вернуть, не просто не.\n","Ирузья все, что все жизни пустота.\n","И не, причины,\n"," не,\n","\n","\n","epoch=6: train_ppl=tensor(5.3058, device='cuda:0') train_epoch_loss=tensor(1.6688, device='cuda:0') eval_ppl=tensor(4.4002, device='cuda:0') eval_epoch_loss=tensor(1.4816, device='cuda:0')\n","\n","\n",",\n",",\n"," свете время,\n","лушайют,\n","сохсеют,\n","И будет так\n"," в нас,\n","И,\n","\n","\n","epoch=7: train_ppl=tensor(5.1153, device='cuda:0') train_epoch_loss=tensor(1.6322, device='cuda:0') eval_ppl=tensor(4.3068, device='cuda:0') eval_epoch_loss=tensor(1.4602, device='cuda:0')\n","\n","\n","\n","epoch=8: train_ppl=tensor(4.9885, device='cuda:0') train_epoch_loss=tensor(1.6071, device='cuda:0') eval_ppl=tensor(4.1986, device='cuda:0') eval_epoch_loss=tensor(1.4348, device='cuda:0')\n","\n",", не,л\n"," свете,И, мамышки,,\n","И человек,алёнокСразучка, спасал.\n","И день онари дрожалжал.И потом ночь с пришёл лес\n","рал.\n","Иит мы крыльцечке, тобойчкой,И сидимиха с лесу кдём.\n","Онбеспоко онскакать кИ гости к навестить себе в.\n","\n"," дня ночи неождали\n","Игдадки разгадать.И ононок не, нет.И онся он\n","од\n","\n","\n","epoch=9: train_ppl=tensor(4.8056, device='cuda:0') train_epoch_loss=tensor(1.5698, device='cuda:0') eval_ppl=tensor(4.1997, device='cuda:0') eval_epoch_loss=tensor(1.4350, device='cuda:0')\n","\n","анную,\n",",, что, бьется битьсядинным,\n","И душевах, Господь\n","Не, помоги,,\n","Не надой меня дитя,ное,\n","Не если него его,уй! прости!\n","Иудья\n","\n","\n","epoch=10: train_ppl=tensor(4.7613, device='cuda:0') train_epoch_loss=tensor(1.5605, device='cuda:0') eval_ppl=tensor(4.0731, device='cuda:0') eval_epoch_loss=tensor(1.4044, device='cuda:0')\n","\n","\n",",рится,\n","но,,\n","Ирыяет,,\n",", сном.\n","Иросыж на небе,,\n","ела,орогшит свой\n","И-ки,\n","окнул хрущит.\n","Имотрилело, трава,ольная.\n","Инежчеттью, словно, как- белаяольная.\n","Инегшены я,-\n",",.\n","И будетольрится тоскусть, чтовит душа.\n","И бы,,, собойюой,\n","И бы,ю я, тобой\n","\n","\n","epoch=11: train_ppl=tensor(4.6943, device='cuda:0') train_epoch_loss=tensor(1.5463, device='cuda:0') eval_ppl=tensor(4.0847, device='cuda:0') eval_epoch_loss=tensor(1.4072, device='cuda:0')\n","\n","\n",",,,, лучшером.рным..\n","Иедвший кусок\n","ённый душиутра,\n","\n"," миг цирка\n"," ты быть и аренеде,\n","Иотовь моя,нута,кой, а в пустота-то гориткое,\n","вое,\n","И на это..\n","И не знаю, я с аду,, кто не мнерикан из\n","И-? - не, враги?И знаю, кто быть быть, я,.\n","Ноть и чём душиш, тобой\n","\n","\n","\n","epoch=12: train_ppl=tensor(4.6318, device='cuda:0') train_epoch_loss=tensor(1.5329, device='cuda:0') eval_ppl=tensor(4.0530, device='cuda:0') eval_epoch_loss=tensor(1.3995, device='cuda:0')\n","\n","\n","\n","epoch=13: train_ppl=tensor(4.5188, device='cuda:0') train_epoch_loss=tensor(1.5083, device='cuda:0') eval_ppl=tensor(4.0193, device='cuda:0') eval_epoch_loss=tensor(1.3911, device='cuda:0')\n",",И\n","\n","рю на,ые постель воду,\n","Иудуылку водки,\n",", хлеб в столе,\n","И столе не нужный закуную дверьель,\n","И не окно вижу зеркалесах,\n"," не тобойсгоном\" в грудишке,\n","Я, что, что яильник, не.И не сне,, как,, то.\n","Ятыедка что ли мнойкой,\n","ьёз меня, чтоЧтовеет,, значит этола,.\n","Аишьпу, что вкамиён,\n","\n","\n","epoch=14: train_ppl=tensor(4.4526, device='cuda:0') train_epoch_loss=tensor(1.4935, device='cuda:0') eval_ppl=tensor(3.9773, device='cuda:0') eval_epoch_loss=tensor(1.3806, device='cuda:0')\n","\n","\n","\n","epoch=15: train_ppl=tensor(4.5034, device='cuda:0') train_epoch_loss=tensor(1.5048, device='cuda:0') eval_ppl=tensor(3.9080, device='cuda:0') eval_epoch_loss=tensor(1.3630, device='cuda:0')\n","В,,о,\n"," неенье,В сердцетах,, не не\n","\n","И в, и сердце меченияхях,\n","И душусказ,сть и печаль,\n","Ишаный мукирия,\n"," боль\n"," не,Наль поворотракрда шаг,\n","Иторый мы какясь, урок,\n","Иожет нам, иль любовьюнойю силойгой\n","Времмиться к победешениюм,ким,\n","И вi,, себе впуай,\n","И не\n","\n","\n","epoch=16: train_ppl=tensor(4.3790, device='cuda:0') train_epoch_loss=tensor(1.4768, device='cuda:0') eval_ppl=tensor(3.9345, device='cuda:0') eval_epoch_loss=tensor(1.3698, device='cuda:0')\n","В,,, не забудетяет.И былен в него\n",",\n","Онас он он земле-нешь,\n","То он его его что нимку.\n","И невинулстав-, решилен.лег.\n","Онть и, горло,ю,,\n","Но еслишает, чтоом он, голодулет,Он,, с, котухой\n","ью\n","\n","Он не рот налилилино) чай) налил налил,\n","Онрызку и кухне горелке.\n","Исолс\n","\n","\n","epoch=17: train_ppl=tensor(4.2901, device='cuda:0') train_epoch_loss=tensor(1.4563, device='cuda:0') eval_ppl=tensor(3.8505, device='cuda:0') eval_epoch_loss=tensor(1.3482, device='cuda:0')\n","\n","\n","\n","epoch=18: train_ppl=tensor(4.3261, device='cuda:0') train_epoch_loss=tensor(1.4647, device='cuda:0') eval_ppl=tensor(3.8821, device='cuda:0') eval_epoch_loss=tensor(1.3564, device='cuda:0')\n","\n","ны, не\n"," не.\n","ИЯ,вая\"\n"," не не.\n","\" не, не не не.\n","\"юсь с собойвым,рением.\n","д\n","юсь.\n","ИЯ,\" я мир, неителен,шен.\n","ИНулевой\" - - это,.\n","\" же их с нимичиной этот,И не неные, детидет\n","\n","\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m      9\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for _ in range(iter_steps):\n","        batch  = next(iter(train_dataloader))\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(**batch, labels=batch[\"input_ids\"])\n","        loss = outputs.loss\n","        total_loss += loss.detach().float()\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    model.eval()\n","    eval_loss = 0\n","    eval_preds = []\n","    for _ in range(iter_steps):\n","        batch  = next(iter(test_dataloader))\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = model(**batch, labels=batch[\"input_ids\"])\n","        loss = outputs.loss\n","        eval_loss += loss.detach().float()\n","        eval_preds.extend(\n","            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n","        )\n","\n","    eval_epoch_loss = eval_loss / (iter_steps)\n","    eval_ppl = torch.exp(eval_epoch_loss)\n","    train_epoch_loss = total_loss / (iter_steps)\n","    train_ppl = torch.exp(train_epoch_loss)\n","    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")\n","    \n","    batch  = next(iter(train_dataloader))\n","    batch = {k: v.to(device) for k, v in batch.items()}\n","    outputs = model(**batch, labels=batch[\"input_ids\"])\n","    print(tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)[0])\n","    print()\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T05:05:23.116538Z","iopub.status.busy":"2024-03-10T05:05:23.115833Z","iopub.status.idle":"2024-03-10T05:05:23.295187Z","shell.execute_reply":"2024-03-10T05:05:23.294247Z","shell.execute_reply.started":"2024-03-10T05:05:23.116505Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","login('')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T05:05:28.731392Z","iopub.status.busy":"2024-03-10T05:05:28.730741Z","iopub.status.idle":"2024-03-10T05:05:31.677842Z","shell.execute_reply":"2024-03-10T05:05:31.676942Z","shell.execute_reply.started":"2024-03-10T05:05:28.731358Z"},"trusted":true},"outputs":[],"source":["peft_model_id = \"aanosov/rugpt3med_PREFIX_CAUSAL_cont256_20ep_5000st_15tokens_stihi\"\n","model.push_to_hub(peft_model_id , use_auth_token=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T05:14:57.686402Z","iopub.status.busy":"2024-03-10T05:14:57.685990Z","iopub.status.idle":"2024-03-10T05:15:00.132443Z","shell.execute_reply":"2024-03-10T05:15:00.131636Z","shell.execute_reply.started":"2024-03-10T05:14:57.686358Z"},"trusted":true},"outputs":[],"source":["from peft import PeftModel, PeftConfig\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","peft_model_id = \"aanosov/rugpt3med_PREFIX_CAUSAL_cont256_20ep_5000st_15tokens_stihi\"\n","config = PeftConfig.from_pretrained(peft_model_id)\n","model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n","model = PeftModel.from_pretrained(model, peft_model_id)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T05:15:07.688318Z","iopub.status.busy":"2024-03-10T05:15:07.687929Z","iopub.status.idle":"2024-03-10T05:15:09.942904Z","shell.execute_reply":"2024-03-10T05:15:09.941903Z","shell.execute_reply.started":"2024-03-10T05:15:07.688287Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Прошла гроза, умылось небо,\n","От туч остались облака,\n","|||\n","Прошлась по морю вода,\n","На земле,\n","Озеро разобилось и лепить,\n","Темно, звёзды теперь бликует,\n","Эту ночь,\n","Остаётся пустеет там,\n","Все равно свет стоит,\n","И луна, и звёзды,\n","Врагу не найти,\n","Видно, что по ней амчуга\n","Находится наводнение,\n","И дырявый барометр\n","Пасмурно небо,\n","И\n"]}],"source":["sentence = \"Прошла гроза, умылось небо,\\nОт туч остались облака,\\n\"\n","context_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n","context = torch.tensor(context_tokens, dtype=torch.long).to(device)\n","num_samples = 1\n","context = context.unsqueeze(0).repeat(num_samples, 1)\n","generated = context\n","\n","length = 100\n","temperature = 0.8\n","with torch.no_grad():\n","    for _ in range(length):\n","        outputs = model(generated)\n","        next_token_logits = outputs[0][:, -1, :] / temperature\n","        next_token = torch.multinomial(F.softmax(next_token_logits, dim=-1), num_samples=1) \n","        generated = torch.cat((generated, next_token), dim=1)\n","\n","out = generated\n","out = out[:, len(context_tokens):].tolist()\n","for o in out:\n","    text = tokenizer.decode(o, clean_up_tokenization_spaces=True)\n","\n","print(sentence+'|||'+text)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T05:15:58.843618Z","iopub.status.busy":"2024-03-10T05:15:58.843231Z","iopub.status.idle":"2024-03-10T05:16:00.714704Z","shell.execute_reply":"2024-03-10T05:16:00.713708Z","shell.execute_reply.started":"2024-03-10T05:15:58.843587Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-03-10T05:16:02.515362Z","iopub.status.busy":"2024-03-10T05:16:02.514995Z","iopub.status.idle":"2024-03-10T05:16:04.648502Z","shell.execute_reply":"2024-03-10T05:16:04.647486Z","shell.execute_reply.started":"2024-03-10T05:16:02.515335Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Прошла гроза, умылось небо,\n","От туч остались облака,\n","|||Чтоб быть все равно не позабыть,\n","Как я тебя люблю. (с)\n","\n","\n","28036259\tcooke\t2016-06-09 13:00:00\t\"Красное и черное\" \n","\n","Одна из самых дорогих кинокартин, которые я когда-либо видел. Фильм снят по мотивам одноименного рассказа Мариво.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]}],"source":["sentence = \"Прошла гроза, умылось небо,\\nОт туч остались облака,\\n\"\n","context_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n","context = torch.tensor(context_tokens, dtype=torch.long).to(device)\n","num_samples = 1\n","context = context.unsqueeze(0).repeat(num_samples, 1)\n","generated = context\n","\n","length = 100\n","temperature = 0.8\n","with torch.no_grad():\n","    for _ in range(length):\n","        outputs = model(generated)\n","        next_token_logits = outputs[0][:, -1, :] / temperature\n","        next_token = torch.multinomial(F.softmax(next_token_logits, dim=-1), num_samples=1) \n","        generated = torch.cat((generated, next_token), dim=1)\n","\n","out = generated\n","out = out[:, len(context_tokens):].tolist()\n","for o in out:\n","    text = tokenizer.decode(o, clean_up_tokenization_spaces=True)\n","\n","print(sentence+'|||'+text)"]},{"cell_type":"markdown","metadata":{},"source":["# CharF"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T08:28:52.291548Z","iopub.status.busy":"2024-03-11T08:28:52.291184Z","iopub.status.idle":"2024-03-11T08:29:16.665897Z","shell.execute_reply":"2024-03-11T08:29:16.664748Z","shell.execute_reply.started":"2024-03-11T08:28:52.291519Z"},"trusted":true},"outputs":[],"source":["!pip install jsonlines\n","!pip install peft"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T08:16:50.340538Z","iopub.status.busy":"2024-03-11T08:16:50.340262Z","iopub.status.idle":"2024-03-11T08:25:17.458358Z","shell.execute_reply":"2024-03-11T08:25:17.457485Z","shell.execute_reply.started":"2024-03-11T08:16:50.340514Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"IlyaGusev/stihi_ru\")\n","dataset = dataset['train'][100000:101000]"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T08:25:46.939173Z","iopub.status.busy":"2024-03-11T08:25:46.938439Z","iopub.status.idle":"2024-03-11T08:25:46.943093Z","shell.execute_reply":"2024-03-11T08:25:46.942041Z","shell.execute_reply.started":"2024-03-11T08:25:46.939142Z"},"trusted":true},"outputs":[],"source":["import random\n","from sklearn.metrics import f1_score\n","from peft import PeftModel, PeftConfig\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from datasets import load_dataset\n","import numpy as np\n","import torch\n","batch_size = 1\n","max_length = 256\n","device='cuda'"]},{"cell_type":"code","execution_count":148,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T10:38:41.066912Z","iopub.status.busy":"2024-03-11T10:38:41.066267Z","iopub.status.idle":"2024-03-11T10:38:43.812391Z","shell.execute_reply":"2024-03-11T10:38:43.811347Z","shell.execute_reply.started":"2024-03-11T10:38:41.066861Z"},"trusted":true},"outputs":[],"source":["peft_model_id = \"aanosov/rugpt3med_PREFIX_CAUSAL_cont256_20ep_5000st_15tokens_stihi\"\n","config = PeftConfig.from_pretrained(peft_model_id)\n","model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n","tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n","model = PeftModel.from_pretrained(model, peft_model_id)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:17:20.041492Z","iopub.status.busy":"2024-03-11T09:17:20.040637Z","iopub.status.idle":"2024-03-11T09:17:20.047297Z","shell.execute_reply":"2024-03-11T09:17:20.046208Z","shell.execute_reply.started":"2024-03-11T09:17:20.041463Z"},"trusted":true},"outputs":[],"source":["test_data = []\n","for full_txt in dataset['text']:\n","    full_txt = '<s>'+full_txt+'</s>'\n","    if len(full_txt) > max_length:\n","        test_data.append(full_txt)"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:17:59.274050Z","iopub.status.busy":"2024-03-11T09:17:59.273283Z","iopub.status.idle":"2024-03-11T09:17:59.281271Z","shell.execute_reply":"2024-03-11T09:17:59.280231Z","shell.execute_reply.started":"2024-03-11T09:17:59.274017Z"},"trusted":true},"outputs":[],"source":["class MyDataLoader:\n","    def __init__(self, data1,  batch_size):\n","        self.batch_size = batch_size\n","        self.data =  data1\n","    \n","    def __iter__(self):\n","        return self\n","    \n","    def __next__(self):\n","        x = []\n","        \n","        batch = [self.data[i] for i in np.random.choice(len(self.data),self.batch_size)]\n","        \n","        for input_txt in batch:\n","            split_token = torch.randint(max_length, len(input_txt), (1,))\n","            x_item = input_txt[split_token-max_length:split_token]\n","            x.append(x_item)\n","\n","        return x\n","\n","test_dataloader = MyDataLoader(test_data, batch_size=batch_size)"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:20:25.263855Z","iopub.status.busy":"2024-03-11T09:20:25.263481Z","iopub.status.idle":"2024-03-11T09:20:25.270531Z","shell.execute_reply":"2024-03-11T09:20:25.269530Z","shell.execute_reply.started":"2024-03-11T09:20:25.263825Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'чально в сердце ложь.\\nПосей любовь внутри себя.\\nУслышишь музыку дождя.\\nЛюбовь в тебе, любовь во мне.\\nОдной мы связкой связаны.\\nГде есть я, там будешь ты.\\nЕсли сердца единой ниткой связаны.\\nБегу я впереди себя.\\nСначала делаю.\\nА думаю потом,\\nспасибо солнышку'"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["a = next(iter(test_dataloader))[0]\n","a"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T09:20:42.521418Z","iopub.status.busy":"2024-03-11T09:20:42.520470Z","iopub.status.idle":"2024-03-11T09:20:42.526399Z","shell.execute_reply":"2024-03-11T09:20:42.525517Z","shell.execute_reply.started":"2024-03-11T09:20:42.521381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ч || а\n","ча || л\n","чал || ь\n","чаль || н\n","чальн || о\n","чально ||  \n","чально  || в\n","чально в ||  \n","чально в  || с\n"]}],"source":["for i in range(1, 10):\n","    print(a[0:i], '||', a[i])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Finetuned model"]},{"cell_type":"code","execution_count":151,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T10:42:05.267739Z","iopub.status.busy":"2024-03-11T10:42:05.267382Z","iopub.status.idle":"2024-03-11T10:52:12.502842Z","shell.execute_reply":"2024-03-11T10:52:12.501852Z","shell.execute_reply.started":"2024-03-11T10:42:05.267709Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.24301960784313725\n"]}],"source":["predictions = []\n","answers = []\n","for _ in range(100):\n","    txt = next(iter(test_dataloader))[0]\n","    for i in range(1, len(txt)):\n","        task = txt[0:i]\n","        answer = txt[i]\n","        tokens = tokenizer(task, add_special_tokens=False, return_tensors=\"pt\")\n","        for k, v in tokens.items():\n","            tokens[k]=v.to(device)\n","        output = tokenizer.decode(model.generate(**tokens, max_new_tokens=1)[0][-1])\n","        predictions.append(output[0])\n","        answers.append(answer)\n","print(f1_score(answers, predictions, average='micro'))"]},{"cell_type":"markdown","metadata":{},"source":["## Original model"]},{"cell_type":"code","execution_count":152,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T10:52:12.505017Z","iopub.status.busy":"2024-03-11T10:52:12.504667Z","iopub.status.idle":"2024-03-11T10:52:14.503865Z","shell.execute_reply":"2024-03-11T10:52:14.502800Z","shell.execute_reply.started":"2024-03-11T10:52:12.504989Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":155,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T10:56:20.771490Z","iopub.status.busy":"2024-03-11T10:56:20.770578Z","iopub.status.idle":"2024-03-11T11:05:53.181867Z","shell.execute_reply":"2024-03-11T11:05:53.180863Z","shell.execute_reply.started":"2024-03-11T10:56:20.771454Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.2826666666666667\n"]}],"source":["predictions = []\n","answers = []\n","for _ in range(100):\n","    txt = next(iter(test_dataloader))[0]\n","    for i in range(1, len(txt)):\n","        task = txt[0:i]\n","        answer = txt[i]\n","        tokens = tokenizer(task, add_special_tokens=False, return_tensors=\"pt\")\n","        for k, v in tokens.items():\n","            tokens[k]=v.to(device)\n","        output = tokenizer.decode(model.generate(**tokens, max_new_tokens=1)[0][-1])\n","        predictions.append(output[0])\n","        answers.append(answer)\n","print(f1_score(answers, predictions, average='micro'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4409001,"sourceId":7573394,"sourceType":"datasetVersion"},{"datasetId":4441402,"sourceId":7624184,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
